**引言**

*   **进程引入带来的好处：**
    *   有效改善资源利用率。
    *   显著提高系统吞吐量。
*   **进程引入带来的复杂性：**
    *   如果不能采取有效措施对多个进程的运行进行妥善管理，必然会因为这些进程对系统资源的无序争夺给系统造成混乱。
    *   导致每次处理的结果存在不确定性，即显现出其**不可再现性**。
*   **进程同步机制的必要性：** 为保证多个进程能有条不紊地运行，在多道程序系统中，必须引入进程同步机制。
*   **本章内容：** 详细介绍单处理机系统中的进程同步机制，包括硬件同步机制、信号量机制、管程机制等，利用它们来保证程序执行的可再现性。

### 2.4.1 进程同步的基本概念

**核心任务：** 进程同步机制的主要任务，是对多个相关进程在执行次序上进行协调，使并发执行的诸进程之间能按照一定的规则（或时序）共享系统资源，并能很好地相互合作，从而使程序的执行具有可再现性。
1.  **两种形式的制约关系 (Two Types of Constraints)**
    在多道程序环境下，对于同处于一个系统中的多个进程，由于它们共享系统中的资源，或为完成某一任务而相互合作，它们之间可能存在以下两种形式的制约关系：
    *   **1) 间接相互制约关系 (Indirect Mutual Restriction)**
        *   **原因：** 多个程序在并发执行时，由于**共享系统资源**（如 CPU、I/O 设备等），致使在这些并发执行的程序之间形成相互制约的关系。
        *   **临界资源 (Critical Resource)：** 对于像打印机、磁带机这样的资源，必须保证多个进程对之只能**互斥地访问 (Mutually Exclusive Access)**。由此，在这些进程间形成了源于对该类资源共享的所谓间接相互制约关系。
        *   **解决方法：** 为了保证这些进程能有序地运行，对于系统中的这类资源，必须由系统实施统一分配，即用户在要使用之前，应先提出申请，而不允许用户进程直接使用。
    *   **2) 直接相互制约关系 (Direct Mutual Restriction)**
        *   **原因：** 某些应用程序，为了完成某任务而建立了两个或多个进程。这些进程将为完成同一项任务而**相互合作 (Cooperation)**。进程间的直接制约关系就是源于它们之间的相互合作。
        *   **示例：输入进程 A 和计算进程 B**
            *   它们之间共享一个缓冲区。
            *   进程 A 通过缓冲向进程 B 提供数据。
            *   进程 B 从缓冲中取出数据，并对数据进行处理。
            *   **制约情况：**
                *   如果该缓冲空时，计算进程因不能获得所需数据而被阻塞（等待 A 输入数据）。一旦进程 A 把数据输入缓冲区后便将进程 B 唤醒。
                *   反之，当缓冲区已满时，进程 A 因不能再向缓冲区投放数据而被阻塞（等待 B 取走数据）。当进程 B 将缓冲区数据取走后便可唤醒 A。
        *   **异步性 (Asynchrony) 的影响：** 在多道程序环境下，由于存在上述两类相互制约关系，进程在运行过程中是否能获得处理机运行与以怎样的速度运行，并不能由进程自身所控制。此即进程的**异步性**。
        *   **与时间有关的错误 ("Time-Related Error")：** 异步性会导致对共享变量或数据结构等资源不正确的访问次序，从而造成进程每次执行结果的不一致。这种差错往往与时间有关，故称为“与时间有关的错误”。
        *   **解决方法：** 为了杜绝这种差错，必须对进程的执行次序进行协调，保证诸进程能按序执行。
2.  **临界资源 (Critical Resource)**
    *   在第一章中已经介绍过，许多硬件资源如打印机、磁带机等，都属于临界资源。
    *   诸进程间应采取**互斥方式**，实现对这种资源的共享。
    *   下面通过一个简单的例子来说明对临界资源（这里指共享变量 `counter`）的互斥访问问题。
    *   **生产者-消费者问题 (Producer-Consumer Problem) 的简化场景：**
        *   一群生产者进程在生产产品，并将这些产品提供给消费者进程去消费。
        *   为使生产者进程与消费者进程能并发执行，在两者之间设置了一个具有 n 个缓冲区的缓冲池。
        *   生产者进程将其所生产的产品放入一个缓冲区中；消费者进程可从一个缓冲区中取走产品去消费。
        *   **共享变量：** `counter`，初始值为 0。每当生产者进程向缓冲池中投放一个产品后，使 `counter` 加 1；每当消费者进程取走一个产品后，使 `counter` 减 1。
        *   **指针：** `in` (输入指针)，`out` (输出指针)，均初始化为 0。缓冲池被组织成循环缓冲。
            *   `in = (in + 1) % n`
            *   `out = (out + 1) % n`
            *   `(in + 1) % n == out` 表示缓冲池满。
            *   `in == out` 表示缓冲池空。
        *   **生产者进程代码片段：**
            ```c
            // ... produce an item in nextp ...
            while (counter == n); // Buffer full, wait
            buffer[in] = nextp;
            in = (in + 1) % n;
            counter++;
            ```
        *   **消费者进程代码片段：**
            ```c
            // ...
            while (counter == 0); // Buffer empty, wait
            nextc = buffer[out];
            out = (out + 1) % n;
            counter--;
            // ... consume the item in nextc ...
            ```
        *   **并发执行的问题：**
            *   虽然生产者和消费者程序在分别看时都是正确的，且两者在顺序执行时其结果也会是正确的，但若并发执行时就会出现差错。
            *   问题在于两个进程共享变量 `counter`。
            *   生产者对它做加 1 操作，消费者对它做减 1 操作。这两个操作在用机器语言实现时，常可用下面的形式描述：
                *   **生产者 (P)：**
                    ```assembly
                    register1 = counter;
                    register1 = register1 + 1;
                    counter = register1;
                    ```
                *   **消费者 (C)：**
                    ```assembly
                    register2 = counter;
                    register2 = register2 - 1;
                    counter = register2;
                    ```
            *   **错误场景举例 (假设 `counter` 当前值为 5)：**
                1.  P: `register1 = counter;` (register1 = 5)
                2.  P: `register1 = register1 + 1;` (register1 = 6)
                3.  C: `register2 = counter;` (register2 = 5)  <-- 此时 `counter` 仍为 5
                4.  C: `register2 = register2 - 1;` (register2 = 4)
                5.  P: `counter = register1;` (counter = 6)
                6.  C: `counter = register2;` (counter = 4)
                *   **结果：** 正确的 `counter` 值应当是 5，但现在是 4。
                *   如果改变 P 和 C 中各语句交叉执行的顺序，还可能得到 `counter=6` 的答案。
            *   **结论：** 程序的执行已经失去了可再现性。
            *   **关键：** 为了预防产生这种错误，关键是应把变量 `counter` 作为临界资源处理，亦即，令生产者进程和消费者进程互斥地访问变量 `counter`。
3.  **临界区 (Critical Section)**

    *   由前所述，不论是硬件临界资源还是软件临界资源，多个进程必须互斥地对它进行访问。
    *   人们把在每个进程中访问临界资源的那段代码称为**临界区 (Critical Section)**。
    *   显然，若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。
    *   为此，每个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问：
        *   如果此刻临界资源未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志。
        *   如果此刻该临界资源正被某进程访问，则本进程不能进入临界区。
    *   因此，必须在临界区前面增加一段用于进行上述检查的代码，把这段代码称为**进入区 (Entry Section)**。
    *   相应地，在临界区后面也要加上一段称为**退出区 (Exit Section)** 的代码，用于将临界区正被访问的标志恢复为未被访问的标志。
    *   进程中除上述进入区、临界区及退出区之外的其它部分的代码在这里都称为**剩余区 (Remainder Section)**。
    *   这样，可把一个访问临界资源的循环进程描述如下：
        ```
        while (TRUE) {
            entry_section();    // 进入区
            critical_section(); // 临界区
            exit_section();     // 退出区
            remainder_section(); // 剩余区
        }
        ```
4.  **同步机制应遵循的规则 (Rules for Synchronization Mechanisms)**
    为实现进程互斥地进入自己的临界区，可用软件方法，更多的是在系统中设置专门的同步机构来协调各进程间的运行。所有同步机制都应遵循下述四条准则：
    *   **(1) 空闲让进 (Idle Allows Entry)：** 当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。
    *   **(2) 忙则等待 (Busy Waits)：** 当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。
    *   **(3) 有限等待 (Bounded Waiting)：** 对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入“死等 (Deadlock-like starvation)”状态。
    *   **(4) 让权等待 (Yielding Wait / Relinquish CPU while Waiting)：** 当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等 (Busy Waiting)”状态。
### 2.4.2 硬件同步机制 (Hardware Synchronization Mechanisms)
虽然可以利用软件方法解决诸进程互斥进入临界区的问题，但有一定难度，并且存在很大的局限性，因而现在已很少采用。相应地，目前许多计算机已提供了一些特殊的硬件指令，允许对一个字中的内容进行检测和修正，或者是对两个字的内容进行交换等。可利用这些特殊的指令来解决临界区问题。
*   **核心思想：** 在对临界区进行管理时，可以将标志看做一个锁，“锁开”进入，“锁关”等待，初始时锁是打开的。每个要进入临界区的进程必须先对锁进行测试，当锁未开时，则必须等待，直至锁被打开。反之，当锁是打开的时候，则应立即把其锁上，以阻止其它进程进入临界区。
*   **原子性要求：** 为防止多个进程同时测试到锁为打开的情况，**测试和关锁操作必须是连续的，不允许分开进行**。
1.  **关中断 (Disabling Interrupts)**
    *   关中断是实现互斥的最简单的方法之一。
    *   在进入锁测试之前关闭中断，直到完成锁测试并上锁之后才能打开中断。
    *   这样，进程在临界区执行期间，计算机系统不响应中断，从而不会引发调度，也就不会发生进程或线程切换。
    *   由此，保证了对锁的测试和关锁操作的连续性和完整性，有效地保证了互斥。
    *   **缺点：**
        *   **① 滥用关中断权力可能导致严重后果。**
        *   **② 关中断时间过长，会影响系统效率，限制了处理器交叉执行程序的能力。**
        *   **③ 关中断方法也不适用于多 CPU 系统，** 因为在一个处理器上关中断并不能防止进程在其它处理器上执行相同的临界段代码。
2.  **利用 Test-and-Set 指令实现互斥**
    *   这是一种借助一条硬件指令——“测试并建立”指令 **TS (Test-and-Set)** 或 **TSL (Test-and-Set Lock)** 以实现互斥的方法。在许多计算机中都提供了这种指令。
    *   **TS 指令的一般性描述：**
        ```c
        boolean TS(boolean *lock) {
            boolean old;
            old = *lock;  // 保存 lock 原来的值
            *lock = TRUE; // 将 lock 设置为 TRUE (上锁)
            return old;   // 返回 lock 原来的值
        }
        ```
    *   **执行过程的原子性：** 这条指令可以看作一个函数过程，其执行过程是**不可分割的 (atomic)**，即是一条原语。
    *   **`lock` 变量的状态：**
        *   `lock = FALSE`：表示该资源空闲。
        *   `lock = TRUE`：表示该资源正在被使用。
    *   **使用 TS 指令管理临界区：**
        *   为每个临界资源设置一个布尔变量 `lock`，由于变量 `lock` 代表了该资源的状态，故可把它看成一把锁。
        *   `lock` 初值为 `FALSE`，表示该临界资源空闲。
        *   进程在进入临界区之前，首先用 TS 指令测试 `lock`：
            *   如果其值为 `FALSE`（TS 返回 `FALSE`），则表示没有进程在临界区内，可以进入，并将 `TRUE` 值赋予 `lock`（上锁），这等效于关闭了临界资源，使任何进程都不能进入临界区。
            *   否则（TS 返回 `TRUE`），必须循环测试直到 `lock` 变为 `FALSE` (即 `TS` 返回 `TRUE` 的情况，表示锁已被占用，需要等待)。
    *   **利用 TS 指令实现互斥的循环进程结构可描述如下：**
        ```c
        // lock 初始化为 FALSE
        do {
            while (TS(&lock)); // 如果 lock 为 TRUE (TS返回TRUE), 则循环 (do skip / no-op)
            critical_section();
            lock = FALSE;       // 释放锁
            remainder_section();
        } while (TRUE);
        ```
3.  **利用 Swap 指令实现进程互斥**
    *   该指令称为对换指令，在 Intel 80x86 中又称为 **XCHG 指令**，用于交换两个字的内容。
    *   **其处理过程描述如下：**
        ```c
        void swap(boolean *a, boolean *b) {
            boolean temp;
            temp = *a;
            *a = *b;
            *b = temp;
        }
        ```
    *   **执行过程的原子性：** `swap` 指令也是一条原语。
    *   **使用 Swap 指令管理临界区：**
        *   为每个临界资源设置一个全局的布尔变量 `lock`，其初值为 `FALSE`。
        *   在每个进程中再利用一个局部布尔变量 `key`。
    *   **利用 Swap 指令实现进程互斥的循环进程可描述如下：**
        ```c
        // lock 初始化为 FALSE (全局)
        do {
            key = TRUE; // 局部变量，表示本进程想进入临界区
            do {
                swap(&lock, &key); // 交换 lock 和 key 的值
                                   // 如果 lock 原来是 FALSE (空闲), 则交换后 lock=TRUE, key=FALSE, 循环退出
                                   // 如果 lock 原来是 TRUE (繁忙), 则交换后 lock=TRUE, key=TRUE, 继续循环
            } while (key != FALSE);
            critical_section();
            lock = FALSE;       // 释放锁
            remainder_section();
        } while (TRUE);
        ```

**硬件同步机制的局限性：**
*   利用上述硬件指令能有效地实现进程互斥，但当临界资源忙碌时，其它访问进程必须不断地进行测试，处于一种**“忙等 (Busy Waiting)”**状态。
*   这种状态不符合“让权等待”的原则，造成处理机时间的浪费。
*   同时也很难将它们用于解决复杂的进程同步问题。
### 2.4.3 信号量机制 (Semaphore Mechanism)
1965年，荷兰学者 Dijkstra 提出了一种卓有成效的进程同步工具——信号量 (Semaphores) 机制。在长期且广泛的应用中，信号量机制又得到了很大的发展，它从整型信号量经记录型信号量，进而发展为“信号量集”机制。现在，信号量机制已被广泛地应用于单处理机和多处理机系统以及计算机网络中。
1.  **整型信号量 (Integer Semaphore)**
    *   最初由 Dijkstra 把整型信号量定义为一个用于表示资源数目的整型量 S。
    *   它与一般整型量不同，除初始化外，仅能通过两个标准的**原子操作 (Atomic Operation) `wait(S)` 和 `signal(S)`** 来访问。很长时间以来，这两个操作一直被分别称为 **P、V 操作**。
    *   **`wait(S)` 操作 (P 操作)：**
        ```c
        wait(S) {
            while (S <= 0); // do no-op (忙等)
            S--;
        }
        ```
        *   如果 `S > 0`，则进程可以继续，并将 S 减 1。
        *   如果 `S <= 0`，则进程必须等待（忙等），直到 S 变为正数。
    *   **`signal(S)` 操作 (V 操作)：**
        ```c
        signal(S) {
            S++;
        }
        ```
        *   将 S 加 1。
    *   **原子性：** `wait(S)` 和 `signal(S)` 是两个原子操作，因此，它们在执行时是不可中断的。亦即，当一个进程在修改某信号量时，没有其它进程可同时对该信号量进行修改。此外，在 `wait` 操作中，对 S 值的测试和做 `S := S - 1` 操作时都不可中断。
    *   **缺点：** 在整型信号量机制中的 `wait` 操作，只要是信号量 `S <= 0`，就会不断地测试。因此，该机制并未遵循“让权等待”的准则，而是使进程处于“忙等”的状态。

2.  **记录型信号量 (Record Semaphore / Blocking Semaphore)**
    *   记录型信号量机制则是一种不存在“忙等”现象的进程同步机制。但在采取了“让权等待”的策略后，又会出现多个进程等待访问同一临界资源的情况。
    *   为此，在信号量机制中，除了需要一个用于代表资源数目的整型变量 `value` 外，还应增加一个**进程链表指针 `list`**，用于链接上述的所有等待进程。
    *   记录型信号量是由于它采用了记录型的数据结构而得名的。它所包含的上述两个数据项可描述如下：
        ```c
        typedef struct {
            int value;                  // 资源计数
            struct process_control_block *list; // 等待队列指针
        } semaphore;
        ```
    *   相应地，`wait(S)` 和 `signal(S)` 操作可描述如下：
        *   **`wait(semaphore *S)` 操作：**
            ```c
            wait(semaphore *S) {
                S->value--;
                if (S->value < 0) { // 如果资源分配后 S->value < 0, 表示无可用资源
                    block(S->list); // 调用 block 原语自我阻塞，并插入到 S->list 链表中
                }
            }
            ```
            *   进程请求一个单位的该类资源，使系统中可供分配的该类资源数减少一个 (`S->value--`)。
            *   当 `S->value < 0` 时，表示该类资源已分配完毕，因此进程应调用 `block` 原语进行自我阻塞，放弃处理机，并插入到信号量链表 `S->list` 中。
            *   可见，该机制遵循了“让权等待”准则。
            *   此时 `S->value` 的绝对值表示在该信号量链表中已阻塞进程的数目。
        *   **`signal(semaphore *S)` 操作：**
            ```c
            signal(semaphore *S) {
                S->value++;
                if (S->value <= 0) { // 如果 S->value <= 0, 表示链表 S->list 中仍有等待该资源的进程被阻塞
                    wakeup(S->list); // 调用 wakeup 原语，将 S->list 链表中的第一个等待进程唤醒
                }
            }
            ```
            *   表示执行进程释放一个单位资源，使系统中可供分配的该类资源数增加一个 (`S->value++`)。
            *   若加 1 后仍是 `S->value <= 0`，则表示在该信号量链表中仍有等待该资源的进程被阻塞，故还应调用 `wakeup` 原语，将 `S->list` 链表中的第一个等待进程唤醒。
        *   **`value` 的初值：**
            *   若 `S->value` 的初值为 1，表示只允许一个进程访问临界资源，此时的信号量转化为**互斥信号量 (Mutex Semaphore)**，用于进程互斥。
            *   若 `S->value` 的初值表示系统中某类资源的数量，则称为**资源信号量**。

3.  **AND 型信号量 (AND Semaphore / Simultaneous P Operation)**
    *   前面所述的进程互斥问题针对的是多个并发进程仅共享一个临界资源的情况。在有些应用场合，一个进程往往需要获得两个或更多的共享资源后方能执行其任务。
    *   **死锁问题：** 假定现有两个进程 A 和 B，它们都要求访问共享数据 D 和 E。如果进程 A 和 B 按下述次序交替执行 `wait` 操作，可能会导致死锁：
        1.  `process A: wait(Dmutex);` (于是 Dmutex=0)
        2.  `process B: wait(Emutex);` (于是 Emutex=0)
        3.  `process A: wait(Emutex);` (于是 Emutex=-1, A 阻塞)
        4.  `process B: wait(Dmutex);` (于是 Dmutex=-1, B 阻塞)
        *   最后，进程 A 和 B 就将处于僵持状态。我们称此时的进程 A 和 B 已进入死锁状态。
    *   **AND 同步机制的基本思想：** 将进程在整个运行过程中需要的所有资源，**一次性全部地分配给进程**，待进程使用完后再一起释放。只要尚有一个资源未能分配给进程，其它所有可能为之分配的资源也不分配给它。亦即，对若干个临界资源的分配采取原子操作方式：要么把它所请求的资源全部分配到进程，要么一个也不分配。
    *   为此，在 `wait` 操作中增加了一个“AND”条件，故称为 AND 同步，或称为同时 `wait` 操作，即 **`Swait (Simultaneous wait)`**。
    *   **`Swait(S1, S2, ..., Sn)` 定义如下：**
        ```c
        Swait(S1, S2, ..., Sn) {
            while (TRUE) {
                if (S1 >= 1 && S2 >= 1 && ... && Sn >= 1) { // 如果所有资源都可用
                    for (i = 1; i <= n; i++) Si--;          // 分配所有资源
                    break;                                 // 成功，退出循环
                } else {
                    // 将进程放入与第一个 Si < 1 的 Si 相关联的等待队列中，
                    // 并设置该进程的程序计数器到 Swait 操作的开始处。
                    // (具体实现涉及阻塞和后续唤醒时重新检查所有条件)
                }
            }
        }
        ```
    *   **`Ssignal(S1, S2, ..., Sn)` 定义如下：** (释放所有资源)
        ```c
        Ssignal(S1, S2, ..., Sn) {
            for (i = 1; i <= n; i++) {
                Si++;
                // 将与 Si 相关联的等待队列中的所有等待进程移入就绪队列
                // (具体实现涉及唤醒等待 Swait 的进程)
            }
        }
        ```

4.  **信号量集 (Semaphore Set)**
    *   在前面所述的记录型信号量机制中，`wait(S)` 或 `signal(S)` 操作仅能对信号量施以加 1 或减 1 操作，意味着每次只能对某类临界资源进行一个单位的申请或释放。当一次需要 N 个单位时，便要进行 N 次 `wait(S)` 操作，这显然是低效的，甚至会增加死锁的概率。
    *   此外，在有些情况下，为确保系统的安全性，当所申请的资源数量低于某一下限值时，还必须进行管制，不予以分配。
    *   基于上述两点，可以对 AND 型信号量机制加以扩充，对进程所申请的所有资源以及每类资源不同的资源需求量，在一次 P、V 原语操作中完成申请或释放。
    *   进程对信号量 Sᵢ 的测试值不再是 1，而是该资源的分配下限值 tᵢ，即要求 Sᵢ ≥ tᵢ，否则不予分配。
    *   一旦允许分配，进程对该资源的需求值为 dᵢ，即表示资源占用量，进行 `Si := Si - di` 操作，而不是简单的 `Si := Si - 1`。
    *   由此形成一般化的“信号量集”机制。对应的 `Swait` 和 `Ssignal` 格式为：
        *   `Swait(S1, t1, d1, ..., Sn, tn, dn);`
        *   `Ssignal(S1, d1, ..., Sn, dn);`
    *   **一般“信号量集”还有下面几种特殊情况：**
        *   **(1) `Swait(S, d, d)`：** 此时在信号量集中只有一个信号量 S，但允许它每次申请 d 个资源，当现有资源数少于 d 时，不予分配。
        *   **(2) `Swait(S, 1, 1)`：** 此时的信号量集已蜕化为一般的记录型信号量（S > 1 时）或互斥信号量（S = 1 时）。
        *   **(3) `Swait(S, 1, 0)`：** 这是一种很特殊且很有用的信号量操作。当 S ≥ 1 时，允许多个进程进入某特定区；当 S 变为 0 后，将阻止任何进程进入特定区。换言之，它相当于一个可控开关。
### 2.4.4 信号量的应用 (Applications of Semaphores)
1.  **利用信号量实现进程互斥 (Mutual Exclusion)**
    *   为使多个进程能互斥地访问某临界资源，只需为该资源设置一**互斥信号量 `mutex`**，并设其初始值为 1。
    *   然后将各进程访问该资源的**临界区 CS** 置于 `wait(mutex)` 和 `signal(mutex)` 操作之间即可。
    *   这样，每个欲访问该临界资源的进程在进入临界区之前，都要先对 `mutex` 执行 `wait` 操作：
        *   若该资源此刻未被访问（`mutex = 1`），本次 `wait` 操作必然成功，进程便可进入自己的临界区。
        *   这时若再有其它进程也欲进入自己的临界区，由于对 `mutex` 执行 `wait` 操作定会失败，因而此时该进程阻塞，从而保证了该临界资源能被互斥地访问。
    *   当访问临界资源的进程退出临界区后，又应对 `mutex` 执行 `signal` 操作，以便释放该临界资源。
    *   **利用信号量实现两个进程互斥的描述如下：**
        ```c
        semaphore mutex = 1; // 初始化互斥信号量
        
        PA() {
            while (1) {
                wait(mutex);
                // 临界区 (Critical Section for PA)
                signal(mutex);
                // 剩余区 (Remainder Section for PA)
            }
        }
        
        PB() {
            while (1) {
                wait(mutex);
                // 临界区 (Critical Section for PB)
                signal(mutex);
                // 剩余区 (Remainder Section for PB)
            }
        }
        ```
        *   **mutex 的取值范围：** (-1, 0, 1)
            *   `mutex = 1`：表示两个进程皆未进入需要互斥的临界区。
            *   `mutex = 0`：表示有一个进程进入临界区运行，另一个必须等待，挂入阻塞队列。
            *   `mutex = -1`：表示有一个进程正在临界区运行，另一个进程因等待而阻塞在信号量队列中，需要被当前已在临界区运行的进程退出时唤醒。
    *   **注意事项：** 在利用信号量机制实现进程互斥时，`wait(mutex)` 和 `signal(mutex)` 必须成对地出现。
        *   缺少 `wait(mutex)` 将会导致系统混乱，不能保证对临界资源的互斥访问。
        *   而缺少 `signal(mutex)` 将会使临界资源永远不被释放，从而使因等待该资源而阻塞的进程不能被唤醒。

2.  **利用信号量实现前趋关系 (Precedence Relation)**
    *   还可利用信号量来描述程序或语句之间的前趋关系。
    *   设有两个并发执行的进程 P₁ 和 P₂。P₁ 中有语句 S₁；P₂ 中有语句 S₂。我们希望在 S₁ 执行后再执行 S₂。
    *   为实现这种前趋关系，只需使进程 P₁ 和 P₂ 共享一个**公用信号量 S**，并赋予其**初值为 0**。
    *   将 `signal(S)` 操作放在语句 S₁ 后面。
    *   而在 S₂ 语句前面插入 `wait(S)` 操作。
        *   **进程 P₁：** `... S1; signal(S); ...`
        *   **进程 P₂：** `... wait(S); S2; ...`
    *   由于 S 被初始化为 0，这样，若 P₂ 先执行，必定在 `wait(S)` 处阻塞。只有在进程 P₁ 执行完 S₁；`signal(S)`；操作后使 S 增为 1 时，P₂ 进程方能成功执行语句 S₂。
    *   **复杂前趋关系示例 (图2-14)：**
	    * ![[image-30.png]]
        *   S₁, S₂, ..., S₆ 是最简单的程序段（只有一条语句）。
        *   为使各程序段能正确执行，应设置若干个初始值为 “0” 的信号量。
        *   如为保证 S₁→S₂，S₁→S₃ 的前趋关系，应分别设置信号量 a 和 b。
        *   同样，为了保证 S₂→S₄，S₂→S₅，S₃→S₆，S₄→S₆ 和 S₅→S₆，应设置信号量 c, d, e, f, g。
        *   **代码框架描述如下：**
        * 
            ```c
            semaphore a=0, b=0, c=0, d=0, e=0, f=0, g=0;
            
            p1() { S1; signal(a); signal(b); }
            p2() { wait(a); S2; signal(c); signal(d); }
            p3() { wait(b); S3; signal(e); }
            p4() { wait(c); S4; signal(f); }
            p5() { wait(d); S5; signal(g); }
            p6() { wait(e); wait(f); wait(g); S6; }
            
            main() {
                // ... semaphore a, b, c, d, e, f, g;
                // a.value=b.value=c.value=0;
                // d.value=e.value=0;
                // f.value=g.value=0;
                cobegin // 并发执行以下进程
                    p1(); p2(); p3(); p4(); p5(); p6();
                coend
            }
            ```
### 2.4.5 管程机制 (Monitor Mechanism)

虽然信号量机制是一种既方便、又有效的进程同步机制，但每个要访问临界资源的进程都必须自备同步操作 `wait(S)` 和 `signal(S)`。这就使大量的同步操作分散在各个进程中。这不仅给系统的管理带来了麻烦，而且还会因同步操作的使用不当而导致系统死锁。这样，在解决上述问题的过程中，便产生了一种新的进程同步工具——**管程 (Monitors)**。
1.  **管程的定义 (Definition of Monitor)**
    *   系统中的各种硬件资源和软件资源均可用数据结构抽象地描述其资源特性，即用少量信息和对该资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。
    *   因此，可以利用共享数据结构抽象地表示系统中的共享资源，并且将对该共享数据结构实施的特定操作定义为一组过程。
    *   进程对共享资源的申请、释放和其它操作必须通过这组过程，间接地对共享数据结构实现操作。
    *   对于请求访问共享资源的诸多并发进程，可以根据资源的情况接受或阻塞，确保每次仅有一个进程进入管程，执行这组过程，使用共享资源，达到对共享资源所有访问的统一管理，有效地实现进程互斥。
    *   **Hansan 为管程所下的定义是：** “一个管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据。”
    *   **组成部分 (图2-15)：**
	    * ![[image-31.png]]
        *   **① 管程的名称。**
        *   **② 局部于管程的共享数据结构说明。**
        *   **③ 对该数据结构进行操作的一组过程（或函数）。**
        *   **④ 对局部于管程的共享数据设置初始值的语句。**
    *   **管程的语法描述如下：**
        ```
        Monitor monitor_name { // 管程名
            // 共享变量说明
            share variable declarations;
            // 条件变量说明 (用于进程同步)
            cond declarations; 
        
            public: // 能被进程调用的过程
                void P1(......) { ...... } // 对数据结构操作的过程
                void P2(......) { ...... }
                // ...
        
            // 管程主体 (初始化代码)
            {
                initialization code; // 初始化代码
            }
        }
        ```
    *   **面向对象思想：** 管程中包含了面向对象的思想，它将表征共享资源的数据结构及其对数据结构操作的一组过程，包括同步机制，都集中并封装在一个对象内部，隐藏了实现细节。
    *   **互斥访问：**
        *   封装于管程内部的数据结构仅能被封装于管程内部的过程所访问，任何管程外的过程都不能访问它。
        *   反之，封装于管程内部的过程也仅能访问管程内的数据结构。
        *   所有进程要访问临界资源时，都只能通过管程间接访问。
        *   **管程每次只准许一个进程进入管程，执行管程内的过程，从而实现了进程互斥。**

2.  **条件变量 (Condition Variables)**
    *   在利用管程实现进程同步时，必须设置同步工具，如两个同步操作原语 `wait` 和 `signal`（这里的 `wait` 和 `signal` 与信号量中的操作不同）。
    *   当某进程通过管程请求获得临界资源而未能满足时，管程便调用 `wait` 原语使该进程等待，并将其排在等待队列上。
    *   仅当另一进程访问完成并释放该资源之后，管程才又调用 `signal` 原语，唤醒等待队列中的队首进程。
    *   **问题：** 仅仅有上述的同步工具是不够的。考虑一种情况：当一个进程调用了管程，在管程中时被阻塞或挂起，直到阻塞或挂起的原因解除。而在此期间，如果该进程不释放管程，则其它进程无法进入管程，被迫长时间的等待。
    *   **解决方案：引入条件变量 `condition`。**
    *   通常，一个进程被阻塞或挂起的条件（原因）可有多个，因此在管程中设置了多个条件变量。
    *   对这些条件变量的访问只能在管程中进行。
    *   **管程中对每个条件变量都须予以说明，其形式为：`condition x, y;`**
    *   对条件变量的操作仅仅是 `x.wait` 和 `x.signal`。因此条件变量也是一种抽象数据类型，每个条件变量保存了一个链表，用于记录因该条件变量而阻塞的所有进程。
    *   **`x.wait`：** 正在调用管程的进程因 x 条件需要被阻塞或挂起，则调用 `x.wait` 将自己插入到 x 条件的等待队列上，并释放管程，直到 x 条件变化。此时其它进程可以使用该管程。
    *   **`x.signal`：** 正在调用管程的进程发现 x 条件发生了变化，则调用 `x.signal`，重新启动一个因 x 条件而阻塞或挂起的进程。如果存在多个这样的进程，则选择其中的一个；如果没有，继续执行原进程，而不产生任何结果。
        *   **与信号量 `signal` 的区别：** 信号量的 `signal` 操作总是要执行 `s:=s+1` 操作，因而总会改变信号量的状态；而管程的 `x.signal` 操作在没有等待进程时，不产生任何影响。
    *   **`x.signal` 后的执行权问题：** 如果有进程 Q 因 x 条件处于阻塞状态，当正在调用管程的进程 P 执行了 `x.signal` 操作后，进程 Q 被重新启动，此时两个进程 P 和 Q，如何确定哪个执行哪个等待，可采用下述两种方式之一进行处理：
        *   **(1) P 等待，直至 Q 离开管程或等待另一条件。** (Hoare 采用的方式)
        *   **(2) Q 等待，直至 P 离开管程或等待另一条件。** (Hansan 采用的方式，规定 `signal` 操作是管程中过程所执行的最后一个操作，于是进程 P 执行 `signal` 操作后立即退出管程，因而进程 Q 马上被恢复执行。)
	**小结：** 进程同步是确保多道程序系统正确、高效运行的关键。从早期的硬件机制到经典的信号量机制，再到更结构化的管程机制，同步工具不断发展，旨在提供更安全、更易用的方式来协调并发进程对共享资源的访问，防止数据不一致和死锁等问题。理解这些机制的原理和应用场景对于设计和分析并发系统至关重要。