
**核心问题：**
文件系统的性能在很大程度上取决于其对文件的访问速度。磁盘 I/O 操作通常远慢于内存访问（可能低4到6个数量级），因此磁盘 I/O 往往成为计算机系统的性能瓶颈。提高磁盘 I/O 速度对于提升整体系统性能至关重要。

**提高文件访问速度的三个主要方面：**

1.  **改进文件目录结构以及检索目录的方法：** 目标是减少对目录的查找时间。这部分内容在前面章节（如文件目录管理）已经有所涉及。
2.  **选取好的文件存储结构（即外存组织方式）：** 目标是优化数据在磁盘上的布局，以提高对文件内容的访问速度。这部分内容在本章的8.1节已经详细讨论。
3.  **提高磁盘本身的 I/O 速度：** 目标是让数据能够更快地从磁盘传送到内存，或者从内存传送到磁盘。本节主要关注这一点。

**提高磁盘 I/O 速度的主要技术途径：**

本节主要介绍通过特定技术手段直接或间接加速磁盘读写操作的方法。最主要的技术是**磁盘高速缓存 (Disk Cache)**。

---

**8.3.1 磁盘高速缓存 (Disk Cache)**

*   **类比与定义：**
    *   类似于CPU高速缓存（用于弥补CPU与主存之间的速度差异），磁盘高速缓存是设置在**内存中**为**磁盘盘块**设置的一个**缓冲区**。
    *   这个缓冲区中保存了**某些磁盘盘块的副本**。
*   **工作原理：**
    1.  当操作系统核心需要访问某个磁盘盘块时（读或写请求）：
    2.  **首先检查磁盘高速缓存：** 查看所请求的盘块内容是否已经存在于缓存中。
    3.  **缓存命中 (Cache Hit)：** 如果请求的盘块在缓存中：
        *   可以直接从高速缓存中获取数据（读操作）或将数据写入缓存（写操作，后续再写回磁盘）。
        *   这样就**避免了启动物理磁盘**进行读写操作，从而大大加快了访问速度（通常能提高几个数量级）。
    4.  **缓存未命中 (Cache Miss)：** 如果请求的盘块不在缓存中：
        *   操作系统需要**启动物理磁盘**，将所需要的盘块内容读入内存（通常先读入一个普通I/O缓冲区）。
        *   然后，将读入的盘块内容**送入磁盘高速缓存**中（通常会替换掉缓存中某个现有的盘块）。
        *   这样做是为了将来再次访问该盘块时能够实现缓存命中。
*   **设计磁盘高速缓存时需要考虑的关键问题：**
    1.  **数据交付 (Data Delivery) 方式：** 如何将高速缓存中的数据传送给请求进程？
    2.  **置换策略 (Replacement Policy)：** 当缓存已满且需要调入新盘块时，选择哪个旧盘块被替换出去？
    3.  **数据写回策略 (Write Policy)：** 已修改的盘块数据在何时被写回到物理磁盘？

    ---
    **1. 数据交付 (Data Delivery) 方式**

    当I/O请求的数据能在磁盘高速缓存中找到（缓存命中）时，需要将缓存中的数据传送给请求者进程。系统可以采取以下两种方式：

    *   **a) 数据复制 (Data Copying / Data Transfer):**
        *   这是最直接的方式。
        *   将高速缓存中相应盘块的数据内容**复制**到请求者进程在内存中指定的工作区（用户缓冲区）。
        *   **缺点：** 涉及数据块的内存复制，当数据量较大时，复制本身也会消耗一定的时间和CPU资源。

    *   **b) 指针交付 (Pointer Passing / Address Passing):**
        *   不进行实际的数据复制。
        *   只将一个**指向高速缓存中该数据区域的指针**交付给请求者进程。
        *   进程可以直接通过这个指针访问缓存中的数据。
        *   **优点：** 由于传送的数据量极少（仅一个指针），因此可以节省数据从高速缓存存储空间到进程内存工作区的时间，效率更高。
        *   **实现考虑：** 需要操作系统内核与用户进程之间有良好的内存共享和访问控制机制。

    ---
    **2. 置换算法 (Replacement Algorithm)**

    当磁盘高速缓存已满，而又需要从磁盘调入一个新的盘块到缓存时，必须选择缓存中的一个或多个现有盘块将其替换出去，以便为新盘块腾出空间。这个选择过程所依据的策略就是置换算法。

    *   **常用算法：**
        *   **最近最久未使用 (LRU - Least Recently Used):** 替换掉最长时间未被访问的盘块。
        *   **最近未使用 (NRU - Not Recently Used):** LRU的一种近似，通常通过访问位和修改位来实现。
        *   **最少使用 (LFU - Least Frequently Used):** 替换掉访问频率最低的盘块。
    *   **与请求调页/段的置换算法的差异和特殊考虑：**
        虽然上述算法在虚拟内存管理中也常用，但在设计磁盘高速缓存的置换算法时，除了考虑“最近最久未使用”原则外，还需要考虑以下几点特殊因素：
        *   **(1) 访问频率 (Access Frequency):**
            *   对**联想存储器**（用于虚拟内存页表加速）的访问频率通常与指令执行频率相当（可能每条指令访问一次）。
            *   而对**磁盘高速缓存**的访问频率则与磁盘I/O的频率相当，远低于联想存储器的访问频率。这意味着盘块在缓存中停留的时间可能相对较长。
        *   **(2) 可预见性 (Predictability):**
            *   在磁盘高速缓存中的各盘块数据，其未来的访问模式在一定程度上是**可预知的**。
            *   例如：
                *   某些类型的盘块（如**二次间接地址块、目录块**）在被访问一次后，可能在较长时间内都不会再被访问。这类块可以作为优先替换的对象。
                *   而某些盘块（如**正在写入数据的未满盘块**，或者顺序读文件时当前块的下一块）则可能很快就会再次被访问。这类块应尽量保留在缓存中。
        *   **(3) 数据的一致性 (Data Consistency):**
            *   磁盘高速缓存位于**易失性存储器**（主存）中。如果系统发生故障（如断电），存放在缓存中但尚未写回磁盘的已修改数据将会丢失。
            *   某些盘块（如**索引节点盘块、目录块、位示图、FAT表**等文件系统元数据）如果被修改但未及时写回，一旦丢失会导致严重的数据不一致性，甚至文件系统损坏。
            *   因此，置换算法需要优先考虑将这些**已修改且对一致性至关重要的盘块**写回磁盘，或者在选择替换时避免替换这类“脏”块。
    *   **一种基于LRU的改进实现：**
        *   将磁盘高速缓存中的所有盘块组织成一条 **LRU 链**。
        *   **特殊处理：**
            *   对于那些**会严重影响数据一致性的盘块**（如已修改的元数据块）和**很久都可能不再使用的盘块**（如刚用过的间接地址块），将它们放在LRU链的**头部**，使其能被优先选中写回磁盘或被替换，以减少数据不一致的风险或尽早释放空间。
            *   对于那些**可能在不久之后便要再次使用的盘块**（如当前正在写入的块），应将其挂在LRU链的**尾部**，以便在需要时能快速找到且不容易被替换。

    ---
    **3. 周期性地写回磁盘 (Write-Back Policy / Periodic Write)**

    当缓存中的盘块数据被修改后（称为“脏块”），它与磁盘上对应盘块的内容就不一致了。这些修改最终需要写回到物理磁盘。

    *   **写回时机：**
        *   **写穿 (Write-Through):** 每次修改缓存中的数据时，立即将其同步写回到磁盘。
            *   优点：数据一致性好，不易丢失。
            *   缺点：写操作频繁，影响性能。
        *   **写回 (Write-Back / Delayed Write):** 修改只在缓存中进行，并不立即写回磁盘。脏块只有在被替换出缓存时，或者在特定条件下才写回磁盘。
            *   优点：减少磁盘写操作次数，提高写性能。多次对同一块的修改可以合并为一次磁盘写。
            *   缺点：如果系统在脏块写回前崩溃，数据可能丢失。
    *   **LRU策略下的问题：**
        *   根据LRU算法，那些经常被访问的盘块数据可能会一直保留在高速缓存中，长期不被替换，因此也长期不会被写回到磁盘。
        *   这是因为LRU链中任一元素在被访问之后，又会被重新挂到链尾。只有一直未被访问的元素才有可能移到链首而被写回或替换。
    *   **UNIX 系统的解决方案：`update` 程序 和 `SYNC` 系统调用**
        *   为了解决上述问题，UNIX系统中专门增设了一个后台运行的**修改程序 (update demon)**。
        *   该程序会**周期性地**（例如，每隔一段时间，如30秒）调用一个名为 **`SYNC` 的系统调用**。
        *   `SYNC` 系统调用的主要功能是**强制性地将所有在高速缓存中已修改过但尚未写回磁盘的“脏”盘块数据全部写回到物理磁盘**。
        *   这样，即使系统发生故障，所造成的工作损失（未保存的数据）通常不会超过两次 `SYNC` 调用之间的时间间隔（如30秒）内所做的工作量。这大大提高了系统的可靠性和数据恢复能力。

---

**8.3.2 提高磁盘 I/O 速度的其它方法**

除了磁盘高速缓存，还有一些其他技术和策略可以用来提高磁盘 I/O 速度：

**1. 提前读 (Read-Ahead / Prefetching)**

*   **适用场景：** 主要针对文件的**顺序访问**模式。
*   **原理：** 当系统检测到进程正在顺序读取文件时，它可以**预知**下一次很可能会读取当前盘块的**下一个盘块**。
*   **操作：**
    *   在读取当前盘块的同时，系统会主动发出请求，将文件的下一个盘块（即**提前读的块**）中的数据也预先读入到内存的某个缓冲区中（通常是磁盘高速缓存的一部分，或者一个专门的预读缓冲区）。
    *   当进程实际需要读取下一个盘块的数据时，由于该数据已经被提前读入内存缓冲区，此时便可直接从缓冲区中获取，而**无需再去启动物理磁盘I/O**。
*   **效果：** 大大减少了顺序读文件时的等待时间，有效地提高了磁盘I/O速度。“提前读”功能已被广泛应用于现代操作系统中。

**2. 延迟写 (Delayed Write)**

*   **原理：** 与磁盘高速缓存的写回策略类似，但可以更广义地应用于任何I/O缓冲区。
    *   当缓冲区A中的数据本应立即写回磁盘时（例如，一个写操作完成），系统考虑到该缓冲区中的数据可能在不久之后再次被本进程或其他进程访问（例如，共享资源）。
    *   因此，系统并**不立即**将缓冲区A中的数据写入磁盘，而是将该缓冲区（标记为“脏”）挂在某个**空闲缓冲区队列的末尾**。
*   **操作：**
    *   随着空闲缓冲区队列中缓冲区的被使用，这个“脏”缓冲区会缓缓地向前移动。
    *   只有当该缓冲区移动到空闲缓冲队列之首，并且再有进程申请使用该缓冲区时，系统才会真正将该缓冲区中的数据写入磁盘，然后才把该缓冲区作为空闲缓冲区分配出去。
*   **效果：**
    *   只要该“脏”缓冲区A仍在队列中时，任何对该缓冲区中数据的访问请求，都可以直接从内存中读出数据，而不必访问磁盘。
    *   这进一步减少了磁盘的I/O次数（特别是写操作和后续的读操作）。“延迟写”功能也已被广泛采用。

**3. 优化物理块的分布 (Optimizing Physical Block Placement)**

*   **适用场景：** 主要针对采用**链接组织方式**和**索引组织方式**的文件。这些方式允许一个文件的盘块分散在磁盘的任意位置。
*   **问题：** 如果文件的盘块分布得过于分散，会导致磁头在读写文件时需要进行大量的、长距离的移动，从而增加寻道时间，降低I/O效率。
    *   例如：文件的第一个盘块在磁盘最内圈的磁道上，而第二个盘块在最外圈的磁道上，读完第一个盘块后，磁头需要从最内圈移动到最外圈才能读取第二个盘块。
*   **优化策略：**
    *   **目标：** 尽量将同一个文件的盘块安排在**同一磁道上**或**相邻的磁道上**。
    *   **实现：** 这种优化应在为文件**分配盘块时**进行。
        *   如果系统中的空白存储空间是采用**位示图**方式表示的，那么要找到一片相邻接的多个空闲盘块是相对容易的。只需在位示图中查找一片连续的“0”位即可。
        *   如果系统采用**线性表（链）法**（如空闲链表）来组织空闲存储空间，要为一个文件分配多个相邻接的盘块就会比较困难。
    *   **簇 (Cluster) 的使用：**
        *   为了在这种情况下也能保证一定的局部性，可以将磁盘上同一磁道上的若干个物理盘块组成一个**簇**（例如，一个簇包含4个盘块）。
        *   在分配存储空间时，以**簇为单位**进行分配。
        *   这样就可以保证在访问这一个簇内的几个盘块时，不必移动磁头，或者仅需在同一磁道内进行短距离移动，从而减少磁头的平均移动距离。

**4. 虚拟盘 (RAM Disk / RAM Drive)**

*   **核心思想：** 利用主存（RAM）的一部分空间来**仿真**一个物理磁盘驱动器。
*   **操作：**
    *   操作系统或专门的软件会在内存中划分出一块区域，并提供一套设备驱动程序，使得这块内存区域在用户和应用程序看来就像一个普通的磁盘驱动器（例如，在Windows中可能显示为一个新的盘符）。
    *   对这个“虚拟盘”的所有读写操作，实际上都是对内存的直接读写。
*   **优点：**
    *   由于内存的访问速度远高于物理磁盘，因此对虚拟盘的I/O操作速度极快。
*   **缺点与问题：**
    *   **易失性 (Volatility)：** 内存是易失性存储器。一旦系统断电或发生故障，或者系统重新启动时，保存在虚拟盘中的所有数据将会**全部丢失**。
    *   **容量有限：** 虚拟盘的大小受限于可用内存的大小。
*   **适用场景：**
    *   通常用于存放**临时文件 (Temporary Files)**，例如：
        *   编译程序产生的中间目标代码文件。
        *   Web浏览器的缓存文件。
        *   需要高速读写但内容非持久性的数据。
*   **与磁盘高速缓存的区别：**
    *   **控制权：** 虚拟盘中的内容完全由**用户（或应用程序）控制**。用户决定何时创建文件、写入数据、删除文件。RAM盘在开始时是空的，仅当用户在RAM盘中创建了文件后，RAM盘中才有内容。
    *   **磁盘高速缓存**中的内容则是由**操作系统 (OS) 控制和管理的**。OS根据缓存算法自动将被访问的磁盘数据调入缓存或写出。用户不能直接控制缓存的内容。

**5. 廉价磁盘冗余阵列 (RAID - Redundant Array of Inexpensive Disks)**
    (教材中将RAID放在8.3.3节，但广义上也属于提高I/O性能和可靠性的重要途径)
      
*   **核心思想：** 将多个小型、廉价的磁盘驱动器组合起来，通过硬件或软件形成一个逻辑上更大的、性能更高或可靠性更强的单一存储设备。
*   **主要目标：**
    *   **提高I/O性能：** 通过并行读写（数据分条存储在多个磁盘上）来实现。
    *   **提高数据可靠性/可用性：** 通过数据冗余（如镜像、奇偶校验）来实现。
*   **并行交叉存取 (Data Striping and Parallel Access):**
    *   这是RAID提高I/O速度的关键技术之一，特别是在RAID 0（条带化）等级中。
    *   系统将每一盘块中的数据（或者一个文件的数据流）分割成若干个**子盘块数据 (strips)**。
    *   然后，将这些子盘块数据**分别存储到阵列中的不同物理磁盘上的相同逻辑位置**（例如，第一个子块存磁盘1，第二个子块存磁盘2，...，第N个子块存磁盘N）。
    *   当需要读取或写入一个完整的盘块（或文件段）时，可以**并行地**从所有相关的物理磁盘上同时读取或写入各自的子盘块数据。
    *   这些子盘块数据在内存中（或通过控制器）合并成原始的盘块数据。
*   **效果：**
    *   如果阵列中有N个磁盘参与并行操作，理论上可以将磁盘I/O的速度提高到接近单个磁盘速度的 N 倍（或 N-1 倍，取决于具体的RAID级别和操作）。
    *   *图8-12 磁盘并行交叉存取方式示例：* 展示了数据如何被分割并分布到多个磁盘上进行并行读写。
	    * ![[Pasted image 20250531150223.png]]
*   **RAID 的分级 (RAID Levels):** RAID有多个级别 (RAID 0, RAID 1, RAID 3, RAID 5, RAID 6, RAID 10等)，每个级别在性能、冗余能力和成本之间有不同的权衡。
    *   **RAID 0 (Striping):** 只做数据分条，无冗余。性能最高，但可靠性最低（一个磁盘坏，所有数据丢失）。
    *   **RAID 1 (Mirroring):** 数据完全镜像到另一个磁盘。可靠性高，写性能可能略降，读性能可能提升，成本高（容量利用率50%）。
    *   其他级别如RAID 5（带分布式奇偶校验的条带化）则在性能、容量和冗余之间取得平衡。

---

